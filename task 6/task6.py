# -*- coding: utf-8 -*-
"""TASK6

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MWx6kwU2VNgMPNXJVMn08qzYqtvP7wVt
"""

#Task-6
# Import libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
nltk.download('vader_lexicon')

# Load the dataset
df = pd.read_csv('/content/disney_plus_titles.csv')

# Display the first few rows of the dataframe
print(df.head())

# 1. Time Series Analysis for Forecasting Trends and Seasonality
# Assuming there's a 'release_year' column
# Convert 'release_year' to datetime
df['release_date'] = pd.to_datetime(df['release_year'], format='%Y')
df.set_index('release_date', inplace=True)

# Plotting the release_year data
df['release_year'].resample('A').count().plot()
plt.title('Number of Titles Released Each Year')
plt.show()

# Decompose the time series for trends and seasonality
result = seasonal_decompose(df['release_year'].resample('A').count(), model='additive')
result.plot()
plt.show()

# 2. Sentiment Analysis or Text Mining on Unstructured Data
# Assuming there's a 'description' column
# Initialize the VADER sentiment analyzer
sia = SentimentIntensityAnalyzer()

# Apply sentiment analysis
df['sentiment'] = df['description'].apply(lambda x: sia.polarity_scores(str(x))['compound'])

# Plot the sentiment scores
sns.histplot(df['sentiment'], bins=20)
plt.title('Sentiment Distribution of Titles Descriptions')
plt.show()

# 3. Clustering or Classification Techniques for Segmentation and Pattern Recognition
# Drop NaN values in 'description' column and reset index
df_clean = df.dropna(subset=['description']).reset_index(drop=True)

# Vectorize the text data
vectorizer = TfidfVectorizer(stop_words='english')
X = vectorizer.fit_transform(df_clean['description'])

# Perform KMeans clustering
kmeans = KMeans(n_clusters=5, random_state=42)
df_clean['cluster'] = kmeans.fit_predict(X)

# Perform PCA for 2D visualization
pca = PCA(n_components=2)
components = pca.fit_transform(X.toarray())

# Create a dataframe with PCA components and cluster labels
pca_df = pd.DataFrame(data=components, columns=['PC1', 'PC2'])
pca_df['cluster'] = df_clean['cluster']

# Plot the clusters
plt.figure(figsize=(10, 6))
sns.scatterplot(x='PC1', y='PC2', hue='cluster', data=pca_df, palette='Set2')
plt.title('Clustering of Titles Based on Descriptions')
plt.show()

